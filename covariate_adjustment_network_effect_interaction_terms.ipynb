{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covariate-adjustment-network-effect-interaction-terms",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgQ1XvvGQaZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "# !pip install -U plotly\n",
        "# import plotly.express as px\n",
        "from urllib.request import urlopen\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "import seaborn as sns\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas\n",
        "import time\n",
        "import io\n",
        "import json\n",
        "\n",
        "#You will need to mount the drive to use the relevant datasets in the shared 'Data' folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt1IjDl8nBHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(ver=2, t_type='unacast'):\n",
        "  if ver == 2:\n",
        "    df_X = pd.read_csv('/content/drive/My Drive/COVID19 Data Exploration /Data/all_X_ver2.csv')\n",
        "    del df_X['Unnamed: 0']\n",
        "    df_Y = pd.read_csv('/content/drive/My Drive/COVID19 Data Exploration /Data/case_diff_Y_v2.csv')\n",
        "    del df_Y['Unnamed: 0']\n",
        "  elif ver == 1:\n",
        "    df_X = pd.read_csv('/content/drive/My Drive/COVID19 Data Exploration /Data/all_X.csv')\n",
        "    del df_X['Unnamed: 0']\n",
        "    df_Y = pd.read_csv('/content/drive/My Drive/COVID19 Data Exploration /Data/case_diff_Y.csv')\n",
        "    del df_Y['Unnamed: 0']\n",
        "\n",
        "  if t_type == 'unacast':\n",
        "    df_T = pd.read_csv('/content/drive/My Drive/COVID19 Data Exploration /Data/unacast_T.csv')\n",
        "    del df_T['Unnamed: 0']\n",
        "  elif t_type == 'safegraph':\n",
        "    df_T = pd.read_csv('/content/drive/My Drive/COVID19 Data Exploration /Data/safegraph_data.csv')\n",
        "  df_T = df_T.rename(columns = {'FIPS-Code':'fips', 'Social_Distance_Change':'score'})\n",
        "\n",
        "  df_X['fips'] = df_X['fips'].astype(float).astype(int)\n",
        "  df_Y['fips'] = df_Y['fips'].astype(float).astype(int)\n",
        "  df_T['fips'] = df_T['fips'].astype(float).astype(int)\n",
        "\n",
        "  return df_X, df_Y, df_T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_TU9ayvS0gK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def construct_dataset(df_X, df_Y, df_T, Y_mode='adj_increase', population_adjustment_factor=1000., num_task=3, t_type='safegraph', \\\n",
        "                      average_y=True):\n",
        "  \"\"\"\n",
        "  Returns dataset as a dict {}\n",
        "  Key: FIPS\n",
        "  Value: Tuple (X, Y, T) where X, Y, T are arrays\n",
        "  \"\"\"\n",
        "  data = {}\n",
        "\n",
        "  score = 'score' if t_type == 'safegraph' else 'unacast_score'\n",
        "  for idx, row in df_X.iterrows():\n",
        "    if len(df_Y.loc[df_Y['fips']==row['fips']]) == 0 or len(df_T.loc[df_T['fips']==row['fips']]) == 0 :\n",
        "      continue\n",
        "    if math.isnan(df_T.loc[df_T['fips']==row['fips']][score].values[0]):\n",
        "      continue\n",
        "    id = row['fips']\n",
        "    x = row.values[3:]\n",
        "    relevant_x = []  \n",
        "    # relevant_x.append(x[0])         # ratio of male\n",
        "    # relevant_x.append(sum(x[2:13])) # ratio of people under 60\n",
        "    relevant_x.append(x[21]) # ratio (%) of african american population\n",
        "    relevant_x.append(x[25]) # ratio of hispanic population\n",
        "    # for k in x[20:26]:\n",
        "    #  relevant_x.append(k) # race distribution \n",
        "    for i, k in enumerate(x[30:37]):\n",
        "      if i==3:\n",
        "        continue\n",
        "      relevant_x.append(k) # 31: poverty, 32: unemployment, 33: median income, 34: pop density, 35: total test per capita, 36: positive test rate, 37: democrat support rate\n",
        "    relevant_x.append(float(x[39]) / float(x[26])) # current confirmed case / capita\n",
        "    relevant_x.append(float(x[40]) / float(x[26])) # current confirmed death / capita\n",
        "\n",
        "    if Y_mode == 'adj_increase':\n",
        "      relevant_x.append(x[42]) # per capita increase during March 23-28\n",
        "    else:\n",
        "      relevant_x.append(x[41])\n",
        "\n",
        "    y1_key = 'Y1_' + Y_mode\n",
        "    y1 = df_Y.loc[df_Y['fips']==id][y1_key].values[0] / 7.0\n",
        "\n",
        "    y2_key = 'Y2_' + Y_mode\n",
        "    y2 = df_Y.loc[df_Y['fips']==id][y2_key].values[0] / 7.0\n",
        "\n",
        "    y3_key = 'Y3_' + Y_mode\n",
        "    y3 = df_Y.loc[df_Y['fips']==id][y3_key].values[0] / 7.0\n",
        "\n",
        "    # average daily case within 5, 10, 15 days\n",
        "    if average_y and Y_mode == 'adj_increase':\n",
        "      y1 = y1\n",
        "      y2 = (y1+y2) / 2.0\n",
        "      y3 = (y3 + 2.0*y2) / 3.0\n",
        "\n",
        "    if Y_mode == 'adj_increase':\n",
        "      y1 *= population_adjustment_factor\n",
        "      y2 *= population_adjustment_factor\n",
        "      y3 *= population_adjustment_factor\n",
        "\n",
        "    y = [y1, y2, y3] if num_task == 3 else ([y1, y2] if num_task == 2 else [y1])\n",
        "\n",
        "    t = df_T.loc[df_T['fips']==id][score].values[0]\n",
        "    # t = 1 if t > 4 else 0 # binarize T (A, B --> 1, C, D, F --> 0)\n",
        "\n",
        "    id_key = \"{:05}\".format(id)\n",
        "    data[id_key] = (relevant_x, y, t)\n",
        "  \n",
        "  return data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cY2uV5XWfYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_X, df_Y, df_T = load_data(ver=2, t_type='unacast')\n",
        "data = construct_dataset(df_X, df_Y, df_T, Y_mode='adj_increase', num_task=3, t_type='unacast')\n",
        "\n",
        "print(len(data))\n",
        "print(data['25025'][0]) # Suffolk County, Massachusetts\n",
        "print(data['25025'][1]) # Suffolk County, Massachusetts\n",
        "print(data['25025'][2]) # Suffolk County, Massachusetts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEvclL63WmQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split Train, Val, Test\n",
        "import random\n",
        "# test = {'0': 0, '1': 1, '2':2, '3':3}\n",
        "# keys = list(test.keys())\n",
        "# shuffledKeys = random.sample(keys, 4)\n",
        "# print(shuffledKeys)\n",
        "\n",
        "def generate_split(keys, val_size=0.1, test_size=0.2):\n",
        "  if val_size + test_size >= 1.0:\n",
        "    raise ValueError(\"Sum of the validation size and the test size should be less than 1\")\n",
        "  shuffled_keys = random.sample(keys, len(keys))\n",
        "\n",
        "  total_len = len(keys)\n",
        "  train_keys = shuffled_keys[:int(total_len*(1-val_size-test_size))]\n",
        "  val_keys = shuffled_keys[int(total_len*(1-val_size-test_size)):int(total_len*(1-test_size))]\n",
        "  test_keys = shuffled_keys[int(total_len*(1-test_size)):]\n",
        "\n",
        "  return train_keys, val_keys, test_keys\n",
        "\n",
        "train_keys, val_keys, test_keys = generate_split(list(data.keys()))\n",
        "print(len(train_keys), len(val_keys), len(test_keys))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0e_I0JibDqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def construct_split_dataset(data, train_keys, val_keys, test_keys, censor_by='all'):\n",
        "  XT_train = []\n",
        "  XT_val = []\n",
        "  XT_test = []\n",
        "\n",
        "  Y_train = []\n",
        "  Y_val= []\n",
        "  Y_test = []\n",
        "\n",
        "  final_train_keys = []\n",
        "  for key in train_keys:\n",
        "    x, y, t = data[key]\n",
        "    y = np.asarray(y)\n",
        "    x = np.asarray(x)\n",
        "    last_three_x = x[len(x)-3:]\n",
        "    flag = (last_three_x[0]> 0 and last_three_x[1]>0 and last_three_x[2]>0) if censor_by == 'all' else (last_three_x[0]> 0 and last_three_x[2]>0)\n",
        "    if not flag:\n",
        "      continue\n",
        "    \n",
        "    feature_interact = t * x\n",
        "    feature = np.insert(x, x.shape[0], t)\n",
        "    feature = np.concatenate((feature, feature_interact))\n",
        "    if np.isnan(feature.sum()):\n",
        "      continue\n",
        "    if np.isnan(y.sum()):\n",
        "      continue\n",
        "    if not (y[0] > 0 and y[1] > 0 and y[2] > 0 ):\n",
        "      continue\n",
        "\n",
        "    XT_train.append(feature)\n",
        "    Y_train.append(y)\n",
        "    final_train_keys.append(key)\n",
        "\n",
        "  final_val_keys = []\n",
        "  for key in val_keys:\n",
        "    x, y, t = data[key]\n",
        "    y = np.asarray(y)\n",
        "    x = np.asarray(x)\n",
        "    last_three_x = x[len(x)-3:]\n",
        "    flag = (last_three_x[0]> 0 and last_three_x[1]>0 and last_three_x[2]>0) if censor_by == 'all' else (last_three_x[0]> 0 and last_three_x[2]>0)\n",
        "    if not flag:\n",
        "      continue\n",
        "\n",
        "    feature_interact = t * x\n",
        "    feature = np.insert(x, x.shape[0], t)\n",
        "    feature = np.concatenate((feature, feature_interact))\n",
        "    if np.isnan(feature.sum()):\n",
        "      continue\n",
        "    if np.isnan(y.sum()):\n",
        "      continue\n",
        "    if not (y[0] > 0 and y[1] > 0 and y[2] > 0):\n",
        "      continue\n",
        "    XT_val.append(feature)\n",
        "    Y_val.append(y)\n",
        "    final_val_keys.append(key)\n",
        "\n",
        "  final_test_keys = []\n",
        "  for key in test_keys:\n",
        "    x, y, t = data[key]\n",
        "    y = np.asarray(y)\n",
        "    x = np.asarray(x)\n",
        "    last_three_x = x[len(x)-3:]\n",
        "    flag = (last_three_x[0]> 0 and last_three_x[1]>0 and last_three_x[2]>0) if censor_by == 'all' else (last_three_x[0]> 0 and last_three_x[2]>0)\n",
        "    if not flag:\n",
        "      continue\n",
        "\n",
        "    feature_interact = t * x\n",
        "    feature = np.insert(x, x.shape[0], t)\n",
        "    feature = np.concatenate((feature, feature_interact))\n",
        "    if np.isnan(feature.sum()):\n",
        "      continue\n",
        "    if np.isnan(y.sum()):\n",
        "      continue\n",
        "    if not (y[0] > 0 and y[1] > 0 and y[2] > 0):\n",
        "      continue\n",
        "    XT_test.append(feature)\n",
        "    Y_test.append(y)\n",
        "    final_test_keys.append(key)\n",
        "\n",
        "  XT_train = np.asarray(XT_train)\n",
        "  XT_val = np.asarray(XT_val)\n",
        "  XT_test = np.asarray(XT_test)\n",
        "  Y_train = np.asarray(Y_train)\n",
        "  Y_val = np.asarray(Y_val)\n",
        "  Y_test = np.asarray(Y_test)\n",
        "  return XT_train, XT_val, XT_test, Y_train, Y_val, Y_test, final_train_keys, final_val_keys, final_test_keys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KJpCNGqeXxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the MultiTaskLasso\n",
        "from sklearn import linear_model, metrics, multioutput, neighbors\n",
        "\n",
        "def train_model(XT_train, Y_train, XT_val, Y_val, scaler, y_scaler, alpha, l1_ratio, y_scale=False, model_type='linear', n_neighbors=20):\n",
        "  if model_type == 'linear':\n",
        "    # model = linear_model.MultiTaskLasso(alpha=alpha, max_iter=100000)\n",
        "    model = linear_model.MultiTaskElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
        "    # model = multioutput.RegressorChain(linear_model.Ridge(alpha=alpha, max_iter=100000))\n",
        "  elif model_type == 'knn':\n",
        "    basemodel = neighbors.KNeighborsRegressor(n_neighbors=n_neighbors, weights='distance')\n",
        "    model = multioutput.RegressorChain(basemodel)\n",
        "  XT_train_transformed = scaler.transform(XT_train)\n",
        "  # print(XT_train_transformed.mean(axis=0))\n",
        "  if y_scale:\n",
        "    Y_train_ = y_scaler.transform(Y_train)\n",
        "  else:\n",
        "    Y_train_ = Y_train\n",
        "\n",
        "  model.fit(XT_train_transformed, Y_train_)\n",
        "\n",
        "  pred = model.predict(XT_train_transformed)\n",
        "  mse = metrics.mean_squared_error(Y_train_, pred)\n",
        "  print(\"Mean Squred Error for the Train Set: {:.4f}\".format(mse))\n",
        "  print(\"R^2 for this model (closer to 1, the better): {:.4f}\".format(model.score(XT_train_transformed, Y_train_)))\n",
        "\n",
        "  XT_val_transformed = scaler.transform(XT_val)\n",
        "  if y_scale:\n",
        "    Y_val_ = y_scaler.transform(Y_val)\n",
        "  else:\n",
        "    Y_val_ = Y_val\n",
        "  pred = model.predict(XT_val_transformed)\n",
        "  mse = metrics.mean_squared_error(Y_val_, pred)\n",
        "  print(\"Mean Squred Error for the Validation Set: {:.4f}\".format(mse))\n",
        "  print(\"R^2 for this model (closer to 1, the better): {:.4f}\".format(model.score(XT_val_transformed, Y_val_)))\n",
        "  # print(\"Printing predictions on the validataion set\")\n",
        "  # print(\"Index , [Ground Truth], [Predicted]\")\n",
        "  # Y_val_ = y_scaler.inverse_transform(Y_val_)\n",
        "  # pred = y_scaler.inverse_transform(pred)\n",
        "  # for idx, (y, p) in enumerate(zip(Y_val_, pred)):\n",
        "  #   print(idx, y, p)\n",
        "\n",
        "  return model\n",
        "\n",
        "def test_model(model, XT, Y, scaler, y_scaler, y_scale=True):\n",
        "  XT_transformed = scaler.transform(XT)\n",
        "  if y_scale:\n",
        "    Y_ = y_scaler.transform(Y)\n",
        "  else:\n",
        "    Y_ = y\n",
        "  pred = model.predict(XT_transformed)\n",
        "  mse = metrics.mean_squared_error(Y_, pred)\n",
        "  print(\"Mean Squred Error for the Test Set: {:.4f}\".format(mse))\n",
        "  print(\"R^2 for this model (closer to 1, the better): {:.4f}\".format(model.score(XT_transformed, Y_)))\n",
        "  print(\"Printing predictions on the validataion set\")\n",
        "  print(\"Index , [Ground Truth], [Predicted]\")\n",
        "  Y_val_ = y_scaler.inverse_transform(Y_)\n",
        "  pred = y_scaler.inverse_transform(pred)\n",
        "  for idx, (y, p) in enumerate(zip(Y_val_, pred)):\n",
        "    print(idx, y, p)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmyIJh6fqHro",
        "colab_type": "text"
      },
      "source": [
        "Including Networking Effect with Simple Markov Assumption"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO3Su0rJrVgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "PATH = '/content/drive/My Drive/COVID19 Data Exploration /Data/county_adjacency.csv'\n",
        "county_df = pd.read_csv(PATH, header=None)\n",
        "county_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkIT8hDksJLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "county_adjacency = {}\n",
        "prev_fips = float('nan')\n",
        "for idx, row in county_df.iterrows():\n",
        "  fips = row[0]\n",
        "  neighbor = row[1]\n",
        "  if math.isnan(fips):\n",
        "    fips = prev_fips\n",
        "  else:\n",
        "    prev_fips = fips\n",
        "  if int(fips) in county_adjacency.keys():\n",
        "    county_adjacency[int(fips)].append(int(neighbor))\n",
        "  else:\n",
        "    county_adjacency[int(fips)] = [int(neighbor)]\n",
        "\n",
        "print(county_adjacency[1001])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iekbuLn0xX0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_data_validity(x, y, t, censor_by):\n",
        "  last_three_x = x[len(x)-3:]\n",
        "  flag = (last_three_x[0]> 0 and last_three_x[1]>0 and last_three_x[2]>0) if censor_by == 'all' else (last_three_x[0]> 0 and last_three_x[2]>0)\n",
        "  if not flag:\n",
        "    return False\n",
        "  feature = np.insert(x, len(x), t)\n",
        "  if np.isnan(feature.sum()):\n",
        "    return False\n",
        "  if np.isnan(y.sum()):\n",
        "    return False\n",
        "  if not (y[0] > 0 and y[1] > 0 and y[2] > 0):\n",
        "    return False\n",
        "\n",
        "  return True\n",
        "\n",
        "def process_data_with_adjacency(data, keys, adjacency, censor_by='all', neighbor_strength=1.0):\n",
        "  XT = []\n",
        "  Y = []\n",
        "  final_keys = []\n",
        "\n",
        "  for key in keys:\n",
        "    x, y, t = data[key]\n",
        "    y = np.asarray(y)\n",
        "    x = np.asarray(x)\n",
        "    valid = check_data_validity(x, y, t, censor_by)\n",
        "    if valid == False:\n",
        "      continue\n",
        "    xt_interact = t * x\n",
        "    xt = np.insert(x, x.shape[0], t)\n",
        "    xt = np.concatenate((xt, xt_interact))\n",
        "    final_keys.append(key)\n",
        "\n",
        "    adj_xt= []\n",
        "    if int(key) in adjacency.keys():\n",
        "      neighbors = adjacency[int(key)]\n",
        "      for n in neighbors:\n",
        "        # Exclude itself\n",
        "        if int(n) == int(key):\n",
        "          continue\n",
        "        if \"{:05}\".format(n) in data.keys():\n",
        "          a_x, a_y, a_t = data[\"{:05}\".format(n)]\n",
        "          a_y = np.asarray(a_y)\n",
        "          a_x = np.asarray(a_x)\n",
        "          a_valid = check_data_validity(a_x, a_y, a_t, censor_by)\n",
        "          if a_valid:\n",
        "            a_xt_interact = a_t * a_x\n",
        "            a_xt = np.insert(a_x, a_x.shape[0], a_t)\n",
        "            a_xt = np.concatenate((a_xt, a_xt_interact))\n",
        "            adj_xt.append(a_xt)\n",
        "      \n",
        "    if len(adj_xt) > 0:\n",
        "      # print(len(adj_xt))\n",
        "      adj_xt = np.asarray(adj_xt)\n",
        "      adj_effect = adj_xt.mean(axis=0)\n",
        "      xt = xt + neighbor_strength * adj_effect\n",
        "    else:\n",
        "      xt = (1 + neighbor_strength) * xt\n",
        "    \n",
        "    XT.append(xt)\n",
        "    Y.append(y)\n",
        "\n",
        "  return XT, Y, final_keys\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPiG36lB2kZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neighbor_XT_train, neighbor_Y_train, neighbor_final_keys = process_data_with_adjacency(data, train_keys, county_adjacency, \\\n",
        "                                                                                       censor_by='death-only', neighbor_strength=1.0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVMshF8CJY1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neighbor_XT_val, neighbor_Y_val, neighbor_final_val = process_data_with_adjacency(data, val_keys, county_adjacency, censor_by='death-only', neighbor_strength=1.0)\n",
        "neighbor_XT_test, neighbor_Y_test, neighbor_final_test = process_data_with_adjacency(data, test_keys, county_adjacency, censor_by='death-only', neighbor_strength=1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v24GIfRM3hBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Standaradization for XT\n",
        "from sklearn import preprocessing\n",
        "scaler = preprocessing.StandardScaler().fit(neighbor_XT_train)\n",
        "y_scaler = preprocessing.StandardScaler().fit(neighbor_Y_train)\n",
        "\n",
        "print(scaler.mean_)\n",
        "print(y_scaler.mean_)\n",
        "\n",
        "for alpha in [0, 1e-3, 2e-3, 5e-3, 1e-2, 2e-2, 5e-2]:\n",
        "  for l1 in [0, 0.01, 0.1, 0.2, 0.5]:\n",
        "    print(alpha, l1)\n",
        "    model = train_model(neighbor_XT_train, neighbor_Y_train, neighbor_XT_val, neighbor_Y_val, scaler, y_scaler, alpha, l1, True)\n",
        "# coef = model.coef_\n",
        "# print(coef)\n",
        "# for i in range(3):\n",
        "#   c = coef[i]\n",
        "#   print(c.shape)\n",
        "#   print(\"------------------------------------\")\n",
        "#   print(\"{}th Task\".format(i))\n",
        "#   # print(\"Sex (Male ratio): {:.5f}\".format(c[0]))\n",
        "#   # print(\"Age (<60 ratio) : {:.5f}\".format(c[1]))\n",
        "#   # print(\"Race - White    : {:.5f}\".format(c[0]))\n",
        "#   print(\"Race - Black    : {:.5f}\".format(c[0]))\n",
        "#   # print(\"Race - Native   : {:.5f}\".format(c[4]))\n",
        "#   # print(\"Race - Pacific  : {:.5f}\".format(c[5]))\n",
        "#   # print(\"Race - Asian    : {:.5f}\".format(c[6]))\n",
        "#   print(\"Race - Hispanic : {:.5f}\".format(c[1]))\n",
        "#   print(\"Bachelor degree : {:.5f}\".format(c[2]))\n",
        "#   print(\"Poverty         : {:.5f}\".format(c[3]))\n",
        "#   print(\"Unemployment    : {:.5f}\".format(c[4]))\n",
        "#   # print(\"Median Income   : {:.5f}\".format(c[7]))\n",
        "#   print(\"Pop density     : {:.5f}\".format(c[5]))\n",
        "#   print(\"Test / capita   : {:.5f}\".format(c[6]))\n",
        "#   print(\"Postive test    : {:.5f}\".format(c[7]))\n",
        "#   # print(\"Politic - Dem   : {:.5f}\".format(c[8]))\n",
        "#   print(\"Covid - Case    : {:.5f}\".format(c[8]))\n",
        "#   print(\"Covid - Death   : {:.5f}\".format(c[9]))\n",
        "#   print(\"Covid - Increase: {:.5f}\".format(c[10]))\n",
        "#   print(\"TREATMENT       : {:.5f}\".format(c[11]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUY-PcPs3vr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = train_model(neighbor_XT_train, neighbor_Y_train, neighbor_XT_val, neighbor_Y_val, scaler, y_scaler, 0.01, 0.5, True)\n",
        "test_model(model, neighbor_XT_test, neighbor_Y_test, scaler, y_scaler, y_scale=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01pw4G_V37me",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZyRhaMpqPxq",
        "colab_type": "text"
      },
      "source": [
        "Analysis: CATE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECOagjl6qx16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cate_measurement(model, scaler, y_scaler, fips, data, df_X, adjacency, neighbor_t=False, censor_by='death-only', neighbor_strength=1.0):\n",
        "  # Return the expected Y's when T is different (1~9 for Unacast)\n",
        "  STNAME = df_X.loc[df_X['fips']==int(fips)]['STNAME'].values[0]\n",
        "  CTYNAME = df_X.loc[df_X['fips']==int(fips)]['CTYNAME'].values[0]\n",
        "  pop = df_X.loc[df_X['fips']==int(fips)]['total_pop'].values[0]\n",
        "\n",
        "  print(\"Fips [{}] {} - {}\".format(fips, STNAME, CTYNAME))\n",
        "  print(\"Total population: {}\".format(pop))\n",
        "  x, y, t = data[fips]\n",
        "  y = np.asarray(y)\n",
        "  x = np.asarray(x)\n",
        "  print(\"Original T: {}\".format(t))\n",
        "  print(\"Original Y1, Y2, Y3: {:.4f}, {:.4f}, {:.4f}\".format(y[0]*100, y[1]*100, y[2]*100))\n",
        "\n",
        "  for tt in range(1, 10):\n",
        "    feature_interact = tt * x\n",
        "    feature = np.insert(x, x.shape[0], tt)\n",
        "    feature = np.concatenate((feature, feature_interact))\n",
        "    adj_xt= []\n",
        "    if int(fips) in adjacency.keys():\n",
        "      neighbors = adjacency[int(fips)]\n",
        "      for n in neighbors:\n",
        "        # Exclude itself\n",
        "        if int(n) == int(fips):\n",
        "          continue\n",
        "        if \"{:05}\".format(n) in data.keys():\n",
        "          a_x, a_y, a_t = data[\"{:05}\".format(n)]\n",
        "          if neighbor_t:\n",
        "            a_t = tt\n",
        "          a_y = np.asarray(a_y)\n",
        "          a_x = np.asarray(a_x)\n",
        "          a_valid = check_data_validity(a_x, a_y, a_t, censor_by)\n",
        "          if a_valid:\n",
        "            a_xt_interact = a_t * a_x\n",
        "            a_xt = np.insert(a_x, a_x.shape[0], a_t)\n",
        "            a_xt = np.concatenate((a_xt, a_xt_interact))\n",
        "            adj_xt.append(a_xt)\n",
        "      \n",
        "    if len(adj_xt) > 0:\n",
        "      # print(len(adj_xt))\n",
        "      adj_xt = np.asarray(adj_xt)\n",
        "      adj_effect = adj_xt.mean(axis=0)\n",
        "      feature = feature + neighbor_strength * adj_effect\n",
        "    else:\n",
        "      feature = (1+neighbor_strength) * feature\n",
        "\n",
        "    XT = scaler.transform(feature.reshape((1, -1)))\n",
        "    pred = model.predict(XT)\n",
        "    pred = y_scaler.inverse_transform(pred)[0]\n",
        "    print(\"When T={}, Y's are: {:.4f}, {:.4f}, {:.4f}\".format(tt, pred[0]*100, pred[1]*100, pred[2]*100))\n",
        "\n",
        "    if tt == 1:\n",
        "      pred_1 = pred\n",
        "    if tt == 9:\n",
        "      pred_9 = pred\n",
        "\n",
        "  return pred_1, pred_9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGKRVkX-tF-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cate_1 = 0\n",
        "cate_2 = 0\n",
        "cate_3 = 0\n",
        "for key in neighbor_final_test:\n",
        "  pred_1, pred_9 = cate_measurement(model, scaler, y_scaler, key, data, df_X, county_adjacency, neighbor_t=True)\n",
        "  print(\"----------------------------------------------------------\")\n",
        "  cate_1 += pred_9[0] - pred_1[0]\n",
        "  cate_2 += pred_9[1] - pred_1[1]\n",
        "  cate_3 += pred_9[2] - pred_1[2]\n",
        "\n",
        "cate_1 /= float(len(neighbor_final_test))\n",
        "cate_2 /= float(len(neighbor_final_test))\n",
        "cate_3 /= float(len(neighbor_final_test))\n",
        "\n",
        "print(cate_1*100, cate_2*100, cate_3*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4p_5VSJtxlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cate_measurement(model, scaler, y_scaler, '25025', data, df_X, county_adjacency, neighbor_t=True)\n",
        "cate_measurement(model, scaler, y_scaler, '25025', data, df_X, county_adjacency, neighbor_t=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x0_Go_ax_xf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}